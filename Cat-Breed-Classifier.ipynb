{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat-Breed Classifier Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total abyssian in training:  402\n",
      "total munchkin in training:  300\n",
      "total persian in training:  398\n",
      "total toyger in training:  370\n",
      "total abyssian in validation:  187\n",
      "total munchkin in validation:  94\n",
      "total persian in validation:  202\n",
      "total toyger in validation:  117\n"
     ]
    }
   ],
   "source": [
    "base_dir='dataset'\n",
    "training_dir=os.path.join(base_dir, 'training')\n",
    "validation_dir=os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_a_dir=os.path.join(training_dir,'abyssian')\n",
    "train_m_dir=os.path.join(training_dir,'munchkin')\n",
    "train_p_dir=os.path.join(training_dir,'persian')\n",
    "train_t_dir=os.path.join(training_dir,'toyger')\n",
    "\n",
    "valid_a_dir=os.path.join(validation_dir,'abyssian')\n",
    "valid_m_dir=os.path.join(validation_dir,'munchkin')\n",
    "valid_p_dir=os.path.join(validation_dir,'persian')\n",
    "valid_t_dir=os.path.join(validation_dir,'toyger')\n",
    "\n",
    "\n",
    "print('total abyssian in training: ', len(os.listdir(train_a_dir)))\n",
    "print('total munchkin in training: ', len(os.listdir(train_m_dir)))\n",
    "print('total persian in training: ', len(os.listdir(train_p_dir)))\n",
    "print('total toyger in training: ', len(os.listdir(train_t_dir)))\n",
    "\n",
    "print('total abyssian in validation: ', len(os.listdir(valid_a_dir)))\n",
    "print('total munchkin in validation: ', len(os.listdir(valid_m_dir)))\n",
    "print('total persian in validation: ', len(os.listdir(valid_p_dir)))\n",
    "print('total toyger in validation: ', len(os.listdir(valid_t_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 513,092\n",
      "Trainable params: 513,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr=1e-4),\n",
    "              loss = 'categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255.,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install git+https://github.com/keras-team/keras.git -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1469 images belonging to 4 classes.\n",
      "Found 600 images belonging to 4 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 59 steps, validate for 30 steps\n",
      "Epoch 1/25\n",
      "59/59 [==============================] - 111s 2s/step - loss: 1.3646 - accuracy: 0.3125 - val_loss: 1.2739 - val_accuracy: 0.4483\n",
      "Epoch 2/25\n",
      "59/59 [==============================] - 98s 2s/step - loss: 1.2598 - accuracy: 0.4105 - val_loss: 1.1823 - val_accuracy: 0.4433\n",
      "Epoch 3/25\n",
      "59/59 [==============================] - 89s 2s/step - loss: 1.2111 - accuracy: 0.4268 - val_loss: 1.0833 - val_accuracy: 0.5333\n",
      "Epoch 4/25\n",
      "59/59 [==============================] - 89s 2s/step - loss: 1.1975 - accuracy: 0.4520 - val_loss: 1.1137 - val_accuracy: 0.4750\n",
      "Epoch 5/25\n",
      "59/59 [==============================] - 89s 2s/step - loss: 1.1622 - accuracy: 0.4615 - val_loss: 1.3182 - val_accuracy: 0.3650\n",
      "Epoch 6/25\n",
      "58/59 [============================>.] - ETA: 1s - loss: 1.1616 - accuracy: 0.4702"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_dir,  # This is the source directory for training images\n",
    "        target_size=(200, 200),  # All images will be resized to 200x200\n",
    "        batch_size=25,\n",
    "        # Since we use sparse_categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(200, 200),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=59,  # 1200 images = batch_size * steps\n",
    "      epochs=25,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=30,\n",
    "     verbose=1\n",
    "      \n",
    ") # 1200 images = batch_size * steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
